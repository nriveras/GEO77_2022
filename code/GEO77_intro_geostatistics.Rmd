---
title: "Exploratory data analysis in R"
author: "Nicolás Riveras Muñoz"
date: "`r format(Sys.time(), '%d %B, %Y, %H:%M')`"
knit: (function(inputFile, encoding) {
  rmarkdown::render(inputFile, encoding = encoding, output_dir = "docs", output_file =  "geostats.html", knit_root_dir = rprojroot::find_rstudio_root_file()) })
output: 
    html_document:
      toc: true
      toc_depth: 3
      toc_float: true
      number_sections: true
      self_contained: yes
      code_folding: show
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
# Spatial modeling

Let's start to explore the data with the tools we already know. In this case, we will use the variable clay as example.

```{r, echo = FALSE}
soil_data <- read.table("data/soil_data.txt", header = TRUE)
```

```{r}
plot(soil_data$x, 
     soil_data$y, 
     cex=soil_data$clay*0.05)
```

We can produce a similar result with more specialized pachages as `sp`

```{r}
library(sp)

# lets make a copy to use the raw data later
soil_data_sp <- soil_data

# We can transform the data as spatial 
coordinates(soil_data_sp) = ~x + y
class(soil_data_sp)

# and give the spatial object to the function bubble
bubble(soil_data_sp,"clay")
```

**Model**:
Limited representation of reality

**Spatial modeling**:
Image of states or processes of locatable objects and their characteristic values

**Data for spatial modeling**:

+   Position in space (e.g. xy-coordinate)
+   Attributes/properties (e.g. sand content, carbon content, N, P, K, etc.)

## Interpolation

We want to interpolate data to fill the gaps where we do not have observations, the way to do this is creating and empty raster and then filling it with the new data.

```{r}
library(gstat)
# Determination of the extension (xmin, xmax, ymin, ymax)
xmin <- min(soil_data$x) - 100
xmax <- max(soil_data$x) + 100
ymin <- min(soil_data$y) - 100
ymax <- max(soil_data$y) + 100
```

**Be careful with the variable cellsize, it determines how many calculations we will do to populate it.

```{r}
# Determination of the resolution (cellsize)
cellsize = 5000

# Spanning a grid (raster format) for interpolation
grd <- expand.grid(x=seq(from = xmin, to = xmax, by = cellsize), 
                   y=seq(from = ymin, to = ymax, by = cellsize))
coordinates(grd) <- ~ x+y
gridded(grd) <- TRUE
```

### IDW

Inverse distance weighted (IDW) interpolation explicitly makes the assumption that things that are close to one another are more alike than those that are farther apart. To predict a value for any unmeasured location, IDW uses the measured values surrounding the prediction location. The measured values closest to the prediction location have more influence on the predicted value than those farther away. IDW assumes that each measured point has a local influence that diminishes with distance. It gives greater weights to points closest to the prediction location, and the weights diminish as a function of distance, hence the name inverse distance weighted. Inverse distance weighted (IDW) interpolation determines cell values using a **linearly** weighted combination of a set of sample points.

[source: How IDW works](https://pro.arcgis.com/de/pro-app/latest/help/analysis/geostatistical-analyst/how-inverse-distance-weighted-interpolation-works.htm)

Gstat library has for this the function 

```{r}

dataset.idw <- idw(soil_data$clay ~ 1, location = ~x+y, soil_data, grd)

image(dataset.idw["var1.pred"], col=topo.colors(20))
points(soil_data$x, soil_data$y)
title("IDW Interpolation of clay content")
```

### Kriging

Kriging is an advanced geostatistical procedure that generates an estimated surface from a scattered set of points with z-values. Kriging is based on statistical models that include autocorrelation—that is, the statistical relationships among the measured points. Because of this, it not only have the capability of producing a prediction surface but also **provide some measure of the certainty or accuracy of the predictions**.

Kriging assumes that the distance or direction between sample points reflects a **spatial correlation** that can be used to explain variation in the surface. The Kriging tool fits a mathematical function to a specified number of points, or all points within a specified radius, to determine the output value for each location. Kriging is a multistep process:

+   exploratory statistical analysis of the data, 
+   variogram modeling, 
+   creating the surface, and 
+   (optionally) exploring a variance surface

[source: How Kriging works](https://pro.arcgis.com/en/pro-app/latest/tool-reference/spatial-analyst/how-kriging-works.htm)

```{r, eval = FALSE, echo=FALSE}
# https://mgimond.github.io/Spatial/interpolation-in-r.html#kriging
```

![](images/Schematic_variogram.svg)


```{r}
# Variogram
v <- variogram(clay ~ 1, locations = ~ x + y, data = soil_data, width = cellsize)
plot(v)
```




```{r}
# Variogram fit
v.fit <- fit.variogram(v, fit.method = TRUE, model = vgm(100, "Sph", 50000, 60))

# Output of the variogram
plot(v, model = v.fit)

```

#### Applying the model fit with the `krige()` function.

```{r}

# ordinary kriging:
z <- krige(formula = clay ~ 1, 
           locations = ~ x + y, 
           data = soil_data, 
           newdata = grd, 
           model = v.fit, 
           nmax = 500)

image(z, col = topo.colors(20))
points(soil_data$x, soil_data$y)
title("Ordinary kriging Interpolation of clay content") 
```

```{r}
# simple kriging:
y <- krige(clay ~ 1, 
           locations = ~ x + y, 
           data = soil_data, 
           newdata = grd, 
           model = v.fit, 
           nmax = 500, 
           beta = mean(soil_data$clay))

image(y, col = topo.colors(20))
points(soil_data$x, soil_data$y)
title("Simple kriging Interpolation of clay content") 
```

Exercise:

+   Tests Simple Kriging in addition to Ordinary Kriging, 
+   Differences theoretically and in visual evaluation?
+   Interpolate OC of the soil_data.txt using ordinary kriging
    +   What model did you use?
    +   What sill?
    +   What range?
    +   What nugget?

#### Model validation

To validate the data, is a good idea to separate the data in train and test data. But...

+   In how many parts should I divide the data?
+   Which of those divisions should I use?

An easy way to solve this is using k-fold-cross-validation, in this case, we will use 10-fold


```{r}

x <- krige.cv(clay ~ 1, 
              locations = ~ x+y, 
              data = soil_data, 
              nfold = 10)

cor(x$observed, x$var1.pred) * cor(x$observed, x$var1.pred) # Rsquared

sqr_error <- (x$var1.pred - x$observed )^2
sqrt(sum(sqr_error)/length(sqr_error))		            # RMSE
```
## Feature extraction

We can also extract data to our points for some already existing raster 


```{r}
library(raster)

# Load a raster stack from an external files
terrain.lst <- list.files("./data/ExampleFromGermany/SAGA", pattern="\\.sdat$", full.names = TRUE)
terrain.raster = raster::stack(terrain.lst)

# plot to see SAGA is working well
plot(terrain.raster$DEM)
plot(terrain.raster)

# set projection of the data points (transformed to spatial object)
proj4string(soil_data_sp) <- CRS("+proj=utm +zone=32 +datum=WGS84 +units=m +no_defs")

# plot the point on the raster
plot(terrain.raster$DEM, main = "DEM + Sample Points")
plot(soil_data_sp, add = TRUE, pch = 1)

# extract values
terrain_cov = raster::extract(terrain.raster,
                              soil_data_sp,
                              method = 'simple')

# combing the covariates + soil data
cov_soil = cbind(data.frame(terrain_cov), clay= soil_data_sp$clay)

# inspect the covariates + soil data 
str(cov_soil)

```
```{r, echo=FALSE, message=FALSE}
library(dplyr)
cov_soil %>%
  kableExtra::kbl() %>%
  kableExtra::kable_classic(full_width = T, html_font = "Cambria", lightable_options = "basic") %>%
  kableExtra::scroll_box(width = "100%", height = "200px")
```

# References

+   [Geocomputation with R](https://geocompr.robinlovelace.net/index.html)
+   [Spatial Data Science with applications in R](https://r-spatial.org/book/)